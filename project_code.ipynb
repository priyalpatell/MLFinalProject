{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBj9MOT6oS4F",
        "outputId": "b977f2e7-e961-4d31-b39b-747fb97ef2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (0.13.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.9.5)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (2.0.3)\n",
            "Requirement already satisfied: packaging in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (20.9)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (2.0.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (3.5.0)\n",
            "Requirement already satisfied: click~=8.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (8.1.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (20.3.0)\n",
            "Requirement already satisfied: certifi in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (52.0.0.post20210125)\n",
            "Requirement already satisfied: cligj>=0.5 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (6.6.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (2021.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.0->geopandas) (1.22.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata->fiona>=1.8.19->geopandas) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from packaging->geopandas) (2.4.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: streamlit in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (1.31.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (4.25.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (5.2.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (1.7.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (1.22.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (15.0.0)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (3.1.42)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (6.1)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (6.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from streamlit) (5.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from altair<6,>=4.0->streamlit) (3.2.0)\n",
            "Requirement already satisfied: toolz in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from altair<6,>=4.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: jinja2 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.4.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (1.15.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (20.3.0)\n",
            "Requirement already satisfied: setuptools in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (52.0.0.post20210125)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from packaging<24,>=16.8->streamlit) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2021.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from jinja2->altair<6,>=4.0->streamlit) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (1.26.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: backports.zoneinfo in /Users/priyal/opt/anaconda3/lib/python3.8/site-packages (from tzlocal<6,>=1.1->streamlit) (0.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install geopandas\n",
        "%pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqqnLWGgtvkF"
      },
      "source": [
        "### **All imports needed to run the program:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TAGfqg89TG9M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gdp\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import streamlit as st\n",
        "import base64\n",
        "\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When will the next UFO sighting be in California?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ga7SH6EvKWp"
      },
      "source": [
        "### **Upload the dataset and extract the relevant column (datetime):**\n",
        "We are only predicting the next UFO sightings in California, so we only need the rows that have 'ca' in their `state` column. Also, we don't need all other columns except for `datetime` to make this prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vyojML2W99a-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"scrubbed.csv\")\n",
        "\n",
        "# List of columns to drop\n",
        "columns_to_drop = ['comments', 'city', 'date posted', 'shape', 'duration (seconds)', 'duration (hours/min)', 'country', 'state', 'latitude', 'longitude ']\n",
        "\n",
        "# Filter for rows where 'state' is 'ca' and 'country' is 'us', and drop specified columns and cities\n",
        "df_filtered = df[(df['state'] == 'ca') & (df['country'] == 'us')].drop(columns=columns_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSwnbXYvYs-"
      },
      "source": [
        "### **Separate ``datetime`` column into two columns ``Date`` and ``Time``:**\n",
        "We are not predicting the exact time of occurence, and therefore we don't need the timing information. However, because the dataset has both date and time together in one column, we want to separate the two and keep the `Date` column only.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LvaKl1X-vnVy",
        "outputId": "4ccd1980-84ec-4775-cdcb-558c71f7d54f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10/10/1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>10/10/1979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>10/10/1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>10/10/1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>10/10/1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80299</th>\n",
              "      <td>9/9/2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80305</th>\n",
              "      <td>9/9/2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80310</th>\n",
              "      <td>9/9/2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80316</th>\n",
              "      <td>9/9/2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80329</th>\n",
              "      <td>9/9/2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8912 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date\n",
              "10     10/10/1968\n",
              "30     10/10/1979\n",
              "45     10/10/1989\n",
              "63     10/10/1995\n",
              "72     10/10/1998\n",
              "...           ...\n",
              "80299    9/9/2012\n",
              "80305    9/9/2012\n",
              "80310    9/9/2012\n",
              "80316    9/9/2013\n",
              "80329    9/9/2013\n",
              "\n",
              "[8912 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_filtered[['Date', 'Time']] = df_filtered['datetime'].str.split(' ', n=1, expand=True)\n",
        "data = df_filtered.drop(columns=['datetime', 'Time'])\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHS_74Fexutg"
      },
      "source": [
        "### **Add extra information to set up for prediction:**\n",
        "Here we add an extra column named `Observed` which shows whether a sighting was observed on the corresponding date. Since we only have the dates of UFO sightings observed, we want to fill the dates in between occurences with 0s to indicate no observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fIVhLFrCLN3L",
        "outputId": "2b1b49df-fab9-4411-a429-774fb4de32b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Observed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1937-08-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1937-08-16</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1937-08-17</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1937-08-18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1937-08-19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28020</th>\n",
              "      <td>2014-05-03</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28021</th>\n",
              "      <td>2014-05-04</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28022</th>\n",
              "      <td>2014-05-05</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28023</th>\n",
              "      <td>2014-05-06</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28024</th>\n",
              "      <td>2014-05-07</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28025 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  Observed\n",
              "0     1937-08-15       1.0\n",
              "1     1937-08-16       0.0\n",
              "2     1937-08-17       0.0\n",
              "3     1937-08-18       0.0\n",
              "4     1937-08-19       0.0\n",
              "...          ...       ...\n",
              "28020 2014-05-03       1.0\n",
              "28021 2014-05-04       1.0\n",
              "28022 2014-05-05       1.0\n",
              "28023 2014-05-06       0.0\n",
              "28024 2014-05-07       1.0\n",
              "\n",
              "[28025 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convert the current date format MM/DD/YYY to YYYY-MM-DD\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "# Add an additional column\n",
        "data['Observed'] = 1\n",
        "# Remove duplicate dates as we don't need them\n",
        "data = data[~data['Date'].duplicated()]\n",
        "# Sort the dates from earliest to latest and fill the rows in between observed dates with 0\n",
        "r = pd.date_range(start=data['Date'].min(), end=data['Date'].max())\n",
        "data = data.set_index('Date').reindex(r).fillna(0.0).rename_axis('Date').reset_index()\n",
        "\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLbjZxiKzaf5"
      },
      "source": [
        "### **Feature engineering:**\n",
        "Prediction of next release dates heavily relies on feature engineering because we do not have any features besides the date itself. Therefore, we add extra columns to feed more information about the dates into our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "8nFDAyH2AHtF",
        "outputId": "d54f9d96-51ec-46e5-bf67-4179254b341c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Observed</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Workday_N</th>\n",
              "      <th>Week_day</th>\n",
              "      <th>Week_of_month</th>\n",
              "      <th>Weekday_order</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1937-08-15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937-08-16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937-08-17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937-08-18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1937-08-19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-03</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-04</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-05</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-05-07</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28025 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Observed  Month  Day  Workday_N  Week_day  Week_of_month  \\\n",
              "Date                                                                   \n",
              "1937-08-15       1.0      8   15         10         6              3   \n",
              "1937-08-16       0.0      8   16         10         0              4   \n",
              "1937-08-17       0.0      8   17         11         1              4   \n",
              "1937-08-18       0.0      8   18         12         2              4   \n",
              "1937-08-19       0.0      8   19         13         3              4   \n",
              "...              ...    ...  ...        ...       ...            ...   \n",
              "2014-05-03       1.0      5    3          2         5              1   \n",
              "2014-05-04       1.0      5    4          2         6              1   \n",
              "2014-05-05       1.0      5    5          2         0              2   \n",
              "2014-05-06       0.0      5    6          3         1              2   \n",
              "2014-05-07       1.0      5    7          4         2              2   \n",
              "\n",
              "            Weekday_order  \n",
              "Date                       \n",
              "1937-08-15              3  \n",
              "1937-08-16              3  \n",
              "1937-08-17              3  \n",
              "1937-08-18              3  \n",
              "1937-08-19              3  \n",
              "...                   ...  \n",
              "2014-05-03              1  \n",
              "2014-05-04              1  \n",
              "2014-05-05              1  \n",
              "2014-05-06              1  \n",
              "2014-05-07              1  \n",
              "\n",
              "[28025 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract/create more information about the dates\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "# The number of business day corresponding to the date (1st business day starts from 0)\n",
        "# for example, 05/07/2014 was the 5th business day of that month, so it's shown as 4 in the chart\n",
        "data['Workday_N'] = np.busday_count(\n",
        "                    data['Date'].values.astype('datetime64[M]'),\n",
        "                    data['Date'].values.astype('datetime64[D]'))\n",
        "# Which day of the week that day was (0 to 6 for Monday to Sunday)\n",
        "# for example, 08/15/1937 was Sunday, so it's shown as 6 in the chart\n",
        "data['Week_day'] = data['Date'].dt.weekday\n",
        "# Which week of the month that month was\n",
        "# for example, the week of 08/16/1937 was the 4th week of that month\n",
        "data['Week_of_month'] = (data['Date'].dt.day\n",
        "                         - data['Date'].dt.weekday - 2) // 7 + 2\n",
        "data['Weekday_order'] = (data['Date'].dt.day + 6) // 7\n",
        "# Set the 'Date' itself as the index for better readability\n",
        "data = data.set_index('Date')\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppx4weda0F9X"
      },
      "source": [
        "### **Train and test split:**\n",
        "Split the preprocessed dataset with a ratio of 70:30 with the ``Observed`` column values as the target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KloaoZvuJPWp"
      },
      "outputs": [],
      "source": [
        "x = data.drop(['Observed'], axis=1)\n",
        "y = data['Observed']  # Target variable\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFURrgYVZxXi"
      },
      "source": [
        "### **Train and test the data:**\n",
        "We used *RandomForestClassifier* because this model often results in higher accuracy compared to individual decision trees, as it reduces overfitting and variance. This is because it builds multiple trees and averages their predictions, which helps generalize well to unseen data.\n",
        "\n",
        "But first, we do GridSearch for the best parameters to get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8feTpikVpzKE",
        "outputId": "786bd198-c4a4-476e-cb95-b59d37e55cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f13fd18b5da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Print classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "source": [
        "# GridSearch parameters:\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Model definition:\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "# Predict using the best model\n",
        "rf_pred = best_model.predict(x_test)\n",
        "# Print classification report\n",
        "print(classification_report(y_test, rf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbCLwEw01Kqo"
      },
      "source": [
        "**Confusion matrix on the training result:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1QQru6IfgRx",
        "outputId": "f4e87025-87cb-4fd9-a338-2786c2e0ddaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "[[6956 1352]\n",
            " [  45   55]]\n",
            "\n",
            "TP: 55\n",
            "TN: 6956\n",
            "FP: 1352\n",
            "FN: 45\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rf_matrix = metrics.confusion_matrix(rf_pred, y_test)\n",
        "tn, fp, fn, tp = rf_matrix.ravel()\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(rf_matrix)\n",
        "print(f\"\\nTP: {tp}\")\n",
        "print(f\"TN: {tn}\")\n",
        "print(f\"FP: {fp}\")\n",
        "print(f\"FN: {fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghrIHZMm1s14"
      },
      "source": [
        "### **Predict future date:**\n",
        "We now create DataFrame with future dates for prediction and use our trained RandomForest model to predict future UFO sightings for one year ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2Z_ar_xnH2_T",
        "outputId": "d4c75541-16a5-41ec-eab2-fdd049fd2659"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2024-06-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2024-06-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2024-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2024-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2024-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prediction       Date\n",
              "0         1.0 2024-06-01\n",
              "1         1.0 2024-06-15\n",
              "2         1.0 2024-06-30\n",
              "3         1.0 2024-07-01\n",
              "4         1.0 2024-07-15"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_predict = pd.DataFrame(pd.date_range(date.today(), (date.today() +\n",
        "            relativedelta(years=1)),freq='d'), columns=['Date'])\n",
        "\n",
        "x_predict['Month'] = x_predict['Date'].dt.month\n",
        "x_predict['Day'] = x_predict['Date'].dt.day\n",
        "x_predict['Workday_N'] = np.busday_count(\n",
        "                x_predict['Date'].values.astype('datetime64[M]'),\n",
        "                x_predict['Date'].values.astype('datetime64[D]'))\n",
        "x_predict['Week_day'] = x_predict['Date'].dt.weekday\n",
        "x_predict['Week_of_month'] = (x_predict['Date'].dt.day -\n",
        "                              x_predict['Date'].dt.weekday - 2)//7+2\n",
        "x_predict['Weekday_order'] = (x_predict['Date'].dt.day + 6) // 7\n",
        "\n",
        "x_predict = x_predict.set_index('Date')\n",
        "prediction = best_model.predict(x_predict)\n",
        "prediction = pd.DataFrame(prediction, columns=['Prediction'])\n",
        "prediction['Date'] = x_predict.index\n",
        "\n",
        "next_sightings = prediction[prediction['Prediction'] == 1]\n",
        "next_sightings = next_sightings.reset_index()\n",
        "next_sightings = next_sightings.drop(columns=['index'])\n",
        "display(next_sightings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Where in California will the next UFO sighting be?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Load the Data & Filter for California Datapoints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>shape</th>\n",
              "      <th>duration (seconds)</th>\n",
              "      <th>duration (hours/min)</th>\n",
              "      <th>comments</th>\n",
              "      <th>date posted</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10/10/1949 20:30</td>\n",
              "      <td>san marcos</td>\n",
              "      <td>tx</td>\n",
              "      <td>us</td>\n",
              "      <td>cylinder</td>\n",
              "      <td>2700</td>\n",
              "      <td>45 minutes</td>\n",
              "      <td>This event took place in early fall around 194...</td>\n",
              "      <td>4/27/2004</td>\n",
              "      <td>29.8830556</td>\n",
              "      <td>-97.941111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10/10/1949 21:00</td>\n",
              "      <td>lackland afb</td>\n",
              "      <td>tx</td>\n",
              "      <td>NaN</td>\n",
              "      <td>light</td>\n",
              "      <td>7200</td>\n",
              "      <td>1-2 hrs</td>\n",
              "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
              "      <td>12/16/2005</td>\n",
              "      <td>29.38421</td>\n",
              "      <td>-98.581082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10/10/1955 17:00</td>\n",
              "      <td>chester (uk/england)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gb</td>\n",
              "      <td>circle</td>\n",
              "      <td>20</td>\n",
              "      <td>20 seconds</td>\n",
              "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
              "      <td>1/21/2008</td>\n",
              "      <td>53.2</td>\n",
              "      <td>-2.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10/10/1956 21:00</td>\n",
              "      <td>edna</td>\n",
              "      <td>tx</td>\n",
              "      <td>us</td>\n",
              "      <td>circle</td>\n",
              "      <td>20</td>\n",
              "      <td>1/2 hour</td>\n",
              "      <td>My older brother and twin sister were leaving ...</td>\n",
              "      <td>1/17/2004</td>\n",
              "      <td>28.9783333</td>\n",
              "      <td>-96.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10/10/1960 20:00</td>\n",
              "      <td>kaneohe</td>\n",
              "      <td>hi</td>\n",
              "      <td>us</td>\n",
              "      <td>light</td>\n",
              "      <td>900</td>\n",
              "      <td>15 minutes</td>\n",
              "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
              "      <td>1/22/2004</td>\n",
              "      <td>21.4180556</td>\n",
              "      <td>-157.803611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           datetime                  city state country     shape  \\\n",
              "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
              "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
              "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
              "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
              "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
              "\n",
              "  duration (seconds) duration (hours/min)  \\\n",
              "0               2700           45 minutes   \n",
              "1               7200              1-2 hrs   \n",
              "2                 20           20 seconds   \n",
              "3                 20             1/2 hour   \n",
              "4                900           15 minutes   \n",
              "\n",
              "                                            comments date posted    latitude  \\\n",
              "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
              "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
              "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
              "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
              "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
              "\n",
              "   longitude   \n",
              "0  -97.941111  \n",
              "1  -98.581082  \n",
              "2   -2.916667  \n",
              "3  -96.645833  \n",
              "4 -157.803611  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ufo = df\n",
        "ufo.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter for datapoints for California sightings\n",
        "ufo = ufo[(ufo['state'] == 'ca') & (ufo['country'] == 'us')]\n",
        "# Drop Nan\n",
        "ufo.dropna(inplace=True)\n",
        "# Rename columns for clarity\n",
        "ufo = ufo.rename(columns = {'duration (seconds)': 'duration_second',\n",
        "    'date posted': 'date_posted', 'longitude ': 'longitude'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split Datetime into New Columns\n",
        "ufo['datetime'] = pd.to_datetime(ufo['datetime'], errors='coerce')\n",
        "ufo.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "ufo.dropna(inplace=True)\n",
        "\n",
        "ufo['datetime_month'] = ufo['datetime'].dt.month.astype(int)\n",
        "ufo['datetime_day'] = ufo['datetime'].dt.day.astype(int)\n",
        "ufo['datetime_year'] = ufo['datetime'].dt.year.astype(int)\n",
        "ufo['datetime_hour'] = ufo['datetime'].dt.hour.astype(int)\n",
        "ufo['datetime_min'] = ufo['datetime'].dt.minute.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Remove Columns Not Used**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop the original 'datetime', 'date_posted', 'comments', 'duration (hours/min)' columns\n",
        "ufo = ufo.drop(columns=['datetime','date_posted','comments','duration (hours/min)', 'state', 'country'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Reducing Shape Column Complexity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Visualizing the most frequently observed UFO shape\n",
        "plt.figure(figsize=(11, 6))\n",
        "sns.countplot(y='shape', data=ufo, palette='viridis')\n",
        "plt.xlabel('UFO Shape')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Types of UFO Seen')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reduce Shape Complexity By Grouping Values\n",
        "print(ufo['shape'].unique())\n",
        "shape = {\n",
        "    'round': ['circle', 'disk', 'sphere', 'round'],\n",
        "    'oval': ['egg', 'oval'],\n",
        "    'triangular': ['triangle', 'cone'],\n",
        "    'rectangular': ['rectangle', 'diamond'],\n",
        "    'light': ['light', 'flash', 'flare'],\n",
        "    'teardrop': ['teardrop', 'fireball'],\n",
        "    'cylindrical': ['cylinder', 'cigar'],\n",
        "    'cross': ['cross'],\n",
        "    'chevron': ['chevron'],\n",
        "    'other': ['other', 'unknown'],\n",
        "    'other2':['formation', 'changing']     \n",
        "}\n",
        "\n",
        "for ufo_shape, ali in shape.items():\n",
        "    ufo.loc[ufo['shape'].isin(ali), 'ufo_shape'] = ufo_shape\n",
        "\n",
        "#Drop original column\n",
        "ufo.drop(columns=['shape'], inplace=True)\n",
        "ufo.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Visualizing Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Convert type columns from object to float\n",
        "ufo['latitude'] = ufo['latitude'].astype('float64')\n",
        "ufo['duration_second'] = ufo['duration_second'].astype('float64')\n",
        "\n",
        "#Create list with columns dtype object\n",
        "object_col = [x for x in ufo.columns if ufo[x].dtype == 'object']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation columns\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.heatmap(ufo.select_dtypes(include=['int64', 'float64']).corr(), annot=True)\n",
        "plt.title('Correlation with Numerical Columns')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot histograms of columns\n",
        "ufo.hist(figsize=(15, 15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hold = ufo.plot(\n",
        "    kind='box', \n",
        "    subplots=True, \n",
        "    sharey=False, \n",
        "    figsize=(10, 6)\n",
        ")\n",
        " \n",
        "# increase spacing between subplots\n",
        "plt.subplots_adjust(wspace=2) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Encoding Columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoding Object Columns\n",
        "ufo_temp = ufo.copy()\n",
        "object_columns = list(ufo_temp.select_dtypes(include='object'))    \n",
        "le = LabelEncoder()\n",
        "for col in object_columns:\n",
        "  ufo_temp[col] = le.fit_transform(ufo_temp[col])\n",
        "ufo_temp.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Split Data into Training & Testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = ufo_temp.drop(columns=['latitude', 'longitude'], axis=1)\n",
        "y_latitude = ufo_temp['latitude']\n",
        "y_longitude = ufo_temp['longitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train_latitude, y_test_latitude, y_train_longitude, y_test_longitude = train_test_split(X, y_latitude, y_longitude, test_size=0.2, random_state=42)\n",
        "mms = MinMaxScaler()\n",
        "X = mms.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model 1: Gradient Boosting Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the models\n",
        "gb_latitude = GradientBoostingRegressor()\n",
        "gb_latitude.fit(X_train, y_train_latitude)\n",
        "\n",
        "gb_longitude = GradientBoostingRegressor()\n",
        "gb_longitude.fit(X_train, y_train_longitude)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_latitude_hgb = gb_latitude.predict(X_test)\n",
        "y_pred_longitude_hgb = gb_longitude.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross Validation\n",
        "cv_results = cross_val_score(gb_latitude, X_train, y_train_latitude, cv=5, scoring='r2')\n",
        "print(\"Latitude Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())\n",
        "cv_results = cross_val_score(gb_longitude, X_train, y_train_longitude, cv=5, scoring='r2')\n",
        "print(\"Longitude Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model 2: Histogram Gradient Boosting Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the models\n",
        "hgb_latitude = HistGradientBoostingRegressor()\n",
        "hgb_latitude.fit(X_train, y_train_latitude)\n",
        "\n",
        "hgb_longitude = HistGradientBoostingRegressor()\n",
        "hgb_longitude.fit(X_train, y_train_longitude)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_latitude_hgb = hgb_latitude.predict(X_test)\n",
        "y_pred_longitude_hgb = hgb_longitude.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross Validation\n",
        "cv_results = cross_val_score(hgb_latitude, X_train, y_train_latitude, cv=5, scoring='r2')\n",
        "print(\"Latitude Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())\n",
        "cv_results = cross_val_score(hgb_longitude, X_train, y_train_longitude, cv=5, scoring='r2')\n",
        "print(\"Longitude Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model 3: Random Forest Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_latitude = RandomForestRegressor()\n",
        "rf_latitude.fit(X_train, y_train_latitude)\n",
        "\n",
        "rf_longitude = RandomForestRegressor()\n",
        "rf_longitude.fit(X_train, y_train_longitude)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_latitude_rf = rf_latitude.predict(X_test)\n",
        "y_pred_longitude_rf = rf_longitude.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross Validation\n",
        "cv_results = cross_val_score(rf_latitude, X_train, y_train_latitude, cv=5, scoring='r2')\n",
        "print(\"Latitude Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())\n",
        "cv_results = cross_val_score(rf_longitude, X_train, y_train_longitude, cv=5, scoring='r2')\n",
        "print(\"Longitude Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After reviewing the cross validation scores from each model, we chose model 3, the random forest regressor, as our final model for question 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the performance\n",
        "mae_latitude_rf = mean_absolute_error(y_test_latitude, y_pred_latitude_rf)\n",
        "mse_latitude_rf = mean_squared_error(y_test_latitude, y_pred_latitude_rf)\n",
        "r2_latitude_rf = r2_score(y_test_latitude, y_pred_latitude_rf)\n",
        "\n",
        "mae_longitude_rf = mean_absolute_error(y_test_longitude, y_pred_longitude_rf)\n",
        "mse_longitude_rf = mean_squared_error(y_test_longitude, y_pred_longitude_rf)\n",
        "r2_longitude_rf = r2_score(y_test_longitude, y_pred_longitude_rf)\n",
        "\n",
        "print(f\"mean_absolute_error latitude: {mae_latitude_rf}\")\n",
        "print(f\"mean_squared_error latitude: {mse_latitude_rf}\")\n",
        "print(f\"r2_score latitude: {r2_latitude_rf}\\n\")\n",
        "print(f\"mean_absolute_error longitude: {mae_longitude_rf}\")\n",
        "print(f\"mean_squared_error longitude: {mse_longitude_rf}\")\n",
        "print(f\"r2_score longitude: {r2_longitude_rf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Optimizing Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = { \n",
        "    'n_estimators': [100, 225, 350],\n",
        "    'max_features': ['sqrt', 'log2', None], \n",
        "} \n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Use random search to find the best hyperparameters\n",
        "rand_search = RandomizedSearchCV(rf, param_distributions=param_grid)\n",
        "\n",
        "# Fit the random search object to the data\n",
        "rand_search.fit(X_train, y_train_latitude)\n",
        "\n",
        "# Create a variable for the best model\n",
        "best_rf = rand_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters:',  rand_search.best_params_)\n",
        "\n",
        "y_pred = best_rf.predict(X_test)\n",
        "r2 = r2_score(y_test_latitude, y_pred)\n",
        "print(\"r2 latitude:\", r2)\n",
        "\n",
        "# Fit the random search object to the data\n",
        "rand_search.fit(X_train, y_train_longitude)\n",
        "\n",
        "# Create a variable for the best model\n",
        "best_rf = rand_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters:',  rand_search.best_params_)\n",
        "\n",
        "y_pred = best_rf.predict(X_test)\n",
        "r2 = r2_score(y_test_longitude, y_pred)\n",
        "print(\"r2 longitude:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross Validation\n",
        "cv_results = cross_val_score(best_rf, X_train, y_train_latitude, cv=5, scoring='r2')\n",
        "print(\"Cross Validation Scores: \", cv_results)\n",
        "print(\"Average CV Score: \", cv_results.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Prediction Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred_lat = pd.DataFrame({'predict_latitude_reg': y_pred_latitude_rf})\n",
        "df_pred_lon = pd.DataFrame({'predict_longitude_reg': y_pred_longitude_rf})\n",
        "\n",
        "ufo_temp['predict_latitude_ufo'] = df_pred_lat['predict_latitude_reg']\n",
        "ufo_temp['predict_longitude_ufo'] = df_pred_lon['predict_longitude_reg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use('dark_background')\n",
        "states = gdp.read_file('cb_2018_us_state_500k/cb_2018_us_state_500k.shp') #223,238,218 #DFEEDA #C8DF5B\n",
        "states[states['NAME'] == 'California'].plot(figsize=(12, 12),color='#DFEEDA') #cmap='Greens')\n",
        "#plt.figure(figsize=(14, 8))\n",
        "plt.scatter(ufo_temp['longitude'], ufo_temp['latitude'], color='#9cc763', label='Real Data', s=3)\n",
        "mask = ~ufo_temp['predict_latitude_ufo'].isnull() & ~ufo_temp['predict_longitude_ufo'].isnull()\n",
        "plt.scatter(ufo_temp.loc[mask, 'predict_longitude_ufo'], ufo_temp.loc[mask, 'predict_latitude_ufo'], color='green', label='Predictions', s=3)\n",
        "plt.title('Real UFO Data vs Predictions', fontsize='18')\n",
        "plt.xlabel('Longitude', fontsize='15')\n",
        "plt.ylabel('Latitude', fontsize='15')\n",
        "plt.xlim(-125, -113)\n",
        "plt.ylim(32, 43)\n",
        "plt.legend(fontsize=\"15\",markerscale=3)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
